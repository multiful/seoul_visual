# app.py â€” ê¸°ê´€ì¢…ë³„ ë¶„í¬ + ê¶Œì—­ ë§‰ëŒ€/ì§€ë„ + ì„±ë³„ ë¶„ì„
# - df_all.csv(í˜¸í¡ê¸° ì „ì²´), pneumonia_data.csv(íë ´ ì „ì²´)
# - ì‚¬ì´ë“œë°”: ì§ˆí™˜ ëŒ€/ì¤‘/ìƒì„¸ í•„í„° + íë ´ ìƒì„¸ì½”ë“œ multiselect
# - í™˜ìë°ì´í„° ê¶Œì—­ ë§¤í•‘ ê²¬ê³ í™”(ì½”ë“œ A/B ìë™ê°ì§€ + ì‹œë„ëª… ë§¤í•‘ + 1~5 ë§¤í•‘)
# - ìš”ì–‘ê¸°ê´€ì¢…ë³„ ì½”ë“œ â†’ ëª…ì¹­ ë§¤í•‘(type_map)
# - 'ìƒìœ„ ê°œìˆ˜' ìŠ¬ë¼ì´ë” ì œê±°(ì „ì²´ í‘œì‹œ)

import json
import re
from pathlib import Path

import numpy as np
import pandas as pd
import geopandas as gpd
import altair as alt
import plotly.express as px
import streamlit as st

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê¸°ë³¸ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(layout="wide", page_title="í™˜ì ëŒ€ì‹œë³´ë“œ", page_icon="ğŸ«")
alt.themes.enable("dark")
st.title("í˜¸í¡ê¸° ì§ˆí™˜ í™˜ì ëŒ€ì‹œë³´ë“œ")
st.caption("all_df=í˜¸í¡ê¸° ì „ì²´, pneumonia_data=íë ´ ì „ì²´ ")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê³µìš© ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def series_to_df(s: pd.Series, value_name: str, index_name: str) -> pd.DataFrame:
    s = s.copy()
    df_tmp = s.to_frame(value_name)
    idx_name = index_name if index_name not in df_tmp.columns else f"{index_name}_idx"
    df_tmp = df_tmp.rename_axis(idx_name).reset_index()
    if idx_name != index_name:
        df_tmp = df_tmp.rename(columns={idx_name: index_name})
    return df_tmp

def map_sex(s):
    s = str(s).strip()
    if s in ("1", "ë‚¨", "male", "Male", "M", "m"): return "ë‚¨"
    if s in ("2", "ì—¬", "female", "Female", "F", "f"): return "ì—¬"
    return np.nan

def normalize_icd(code) -> str:
    if code is None or (isinstance(code, float) and np.isnan(code)):
        return ""
    return re.sub(r"[^A-Za-z0-9]", "", str(code)).upper()

def first2digits(x: str) -> str:
    s = re.sub(r"\D", "", str(x))
    return s[:2] if len(s) >= 2 else s.zfill(2)

# ì‹œë„ëª… ì •ê·œí™”(ì ‘ë¯¸ì‚¬ ì œê±°)
def norm_nm(s: str) -> str:
    s = re.sub(r"\s+", "", str(s))
    for t in ['íŠ¹ë³„ìì¹˜ë„','íŠ¹ë³„ìì¹˜ì‹œ','íŠ¹ë³„ì‹œ','ê´‘ì—­ì‹œ','ìì¹˜ë„','ë„','ì‹œ']:
        s = s.replace(t, '')
    return s

# â”€â”€ ì‹œë„ ì½”ë“œì²´ê³„(A/B) ë§¤í•‘(ì§€ë„/í™˜ì ê³µí†µ)
CODE_TO_REGION_A = {
    "11": "ì„œìš¸,ì¸ì²œ", "23": "ì„œìš¸,ì¸ì²œ",
    "31": "ê²½ê¸°,ê°•ì›", "32": "ê²½ê¸°,ê°•ì›",
    "33": "ì¶©ì²­ê¶Œ(ì¶©ë¶, ì¶©ë‚¨, ì„¸ì¢…, ëŒ€ì „)", "34": "ì¶©ì²­ê¶Œ(ì¶©ë¶, ì¶©ë‚¨, ì„¸ì¢…, ëŒ€ì „)",
    "25": "ì¶©ì²­ê¶Œ(ì¶©ë¶, ì¶©ë‚¨, ì„¸ì¢…, ëŒ€ì „)", "29": "ì¶©ì²­ê¶Œ(ì¶©ë¶, ì¶©ë‚¨, ì„¸ì¢…, ëŒ€ì „)",
    "35": "ì „ë¼ê¶Œ(ì „ë¶, ì „ë‚¨, ê´‘ì£¼)", "36": "ì „ë¼ê¶Œ(ì „ë¶, ì „ë‚¨, ê´‘ì£¼)", "24": "ì „ë¼ê¶Œ(ì „ë¶, ì „ë‚¨, ê´‘ì£¼)",
    "21": "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)", "22": "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)",
    "26": "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)", "37": "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)",
    "38": "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)", "39": "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)",
}
CODE_TO_REGION_B = {
    "11": "ì„œìš¸,ì¸ì²œ", "28": "ì„œìš¸,ì¸ì²œ",
    "41": "ê²½ê¸°,ê°•ì›", "42": "ê²½ê¸°,ê°•ì›",
    "43": "ì¶©ì²­ê¶Œ(ì¶©ë¶, ì¶©ë‚¨, ì„¸ì¢…, ëŒ€ì „)", "44": "ì¶©ì²­ê¶Œ(ì¶©ë¶, ì¶©ë‚¨, ì„¸ì¢…, ëŒ€ì „)",
    "36": "ì¶©ì²­ê¶Œ(ì¶©ë¶, ì¶©ë‚¨, ì„¸ì¢…, ëŒ€ì „)", "30": "ì¶©ì²­ê¶Œ(ì¶©ë¶, ì¶©ë‚¨, ì„¸ì¢…, ëŒ€ì „)",
    "45": "ì „ë¼ê¶Œ(ì „ë¶, ì „ë‚¨, ê´‘ì£¼)", "46": "ì „ë¼ê¶Œ(ì „ë¶, ì „ë‚¨, ê´‘ì£¼)", "29": "ì „ë¼ê¶Œ(ì „ë¶, ì „ë‚¨, ê´‘ì£¼)",
    "47": "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)", "48": "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)",
    "26": "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)", "27": "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)",
    "31": "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)", "50": "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)",
}
NAME_TO_REGION = {
    "ì„œìš¸íŠ¹ë³„ì‹œ": "ì„œìš¸,ì¸ì²œ", "ì¸ì²œê´‘ì—­ì‹œ": "ì„œìš¸,ì¸ì²œ",
    "ê²½ê¸°ë„": "ê²½ê¸°,ê°•ì›", "ê°•ì›íŠ¹ë³„ìì¹˜ë„": "ê²½ê¸°,ê°•ì›", "ê°•ì›ë„": "ê²½ê¸°,ê°•ì›",
    "ì¶©ì²­ë¶ë„": "ì¶©ì²­ê¶Œ(ì¶©ë¶, ì¶©ë‚¨, ì„¸ì¢…, ëŒ€ì „)", "ì¶©ì²­ë‚¨ë„": "ì¶©ì²­ê¶Œ(ì¶©ë¶, ì¶©ë‚¨, ì„¸ì¢…, ëŒ€ì „)",
    "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ": "ì¶©ì²­ê¶Œ(ì¶©ë¶, ì¶©ë‚¨, ì„¸ì¢…, ëŒ€ì „)", "ëŒ€ì „ê´‘ì—­ì‹œ": "ì¶©ì²­ê¶Œ(ì¶©ë¶, ì¶©ë‚¨, ì„¸ì¢…, ëŒ€ì „)",
    "ì „ë¶íŠ¹ë³„ìì¹˜ë„": "ì „ë¼ê¶Œ(ì „ë¶, ì „ë‚¨, ê´‘ì£¼)", "ì „ë¼ë¶ë„": "ì „ë¼ê¶Œ(ì „ë¶, ì „ë‚¨, ê´‘ì£¼)",
    "ì „ë¼ë‚¨ë„": "ì „ë¼ê¶Œ(ì „ë¶, ì „ë‚¨, ê´‘ì£¼)", "ê´‘ì£¼ê´‘ì—­ì‹œ": "ì „ë¼ê¶Œ(ì „ë¶, ì „ë‚¨, ê´‘ì£¼)",
    "ê²½ìƒë¶ë„": "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)", "ê²½ìƒë‚¨ë„": "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)",
    "ë¶€ì‚°ê´‘ì—­ì‹œ": "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)", "ëŒ€êµ¬ê´‘ì—­ì‹œ": "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)",
    "ìš¸ì‚°ê´‘ì—­ì‹œ": "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)", "ì œì£¼íŠ¹ë³„ìì¹˜ë„": "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)",
}
# ì •ê·œí™”ëœ ì´ë¦„ â†’ ê¶Œì—­(ì—¬ë¶„ ë°±ì—…ìš©)
NORMNAME_TO_REGION = {
    'ì„œìš¸': "ì„œìš¸,ì¸ì²œ", 'ì¸ì²œ': "ì„œìš¸,ì¸ì²œ",
    'ê²½ê¸°': "ê²½ê¸°,ê°•ì›", 'ê°•ì›': "ê²½ê¸°,ê°•ì›",
    'ì¶©ë¶': "ì¶©ì²­ê¶Œ(ì¶©ë¶, ì¶©ë‚¨, ì„¸ì¢…, ëŒ€ì „)", 'ì¶©ë‚¨': "ì¶©ì²­ê¶Œ(ì¶©ë¶, ì¶©ë‚¨, ì„¸ì¢…, ëŒ€ì „)",
    'ì„¸ì¢…': "ì¶©ì²­ê¶Œ(ì¶©ë¶, ì¶©ë‚¨, ì„¸ì¢…, ëŒ€ì „)", 'ëŒ€ì „': "ì¶©ì²­ê¶Œ(ì¶©ë¶, ì¶©ë‚¨, ì„¸ì¢…, ëŒ€ì „)",
    'ì „ë¶': "ì „ë¼ê¶Œ(ì „ë¶, ì „ë‚¨, ê´‘ì£¼)", 'ì „ë‚¨': "ì „ë¼ê¶Œ(ì „ë¶, ì „ë‚¨, ê´‘ì£¼)", 'ê´‘ì£¼': "ì „ë¼ê¶Œ(ì „ë¶, ì „ë‚¨, ê´‘ì£¼)",
    'ê²½ë¶': "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)", 'ê²½ë‚¨': "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)",
    'ë¶€ì‚°': "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)", 'ëŒ€êµ¬': "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)",
    'ìš¸ì‚°': "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)", 'ì œì£¼': "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)",
}

REGION_MAP_1TO5 = {
    1: "ì„œìš¸,ì¸ì²œ",
    2: "ê²½ê¸°,ê°•ì›",
    3: "ì¶©ì²­ê¶Œ(ì¶©ë¶, ì¶©ë‚¨, ì„¸ì¢…, ëŒ€ì „)",
    4: "ì „ë¼ê¶Œ(ì „ë¶, ì „ë‚¨, ê´‘ì£¼)",
    5: "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)",
}
VALID_REGIONS = list(REGION_MAP_1TO5.values())
REGION_SIDO_N = {"ì„œìš¸,ì¸ì²œ": 2, "ê²½ê¸°,ê°•ì›": 2, "ì¶©ì²­ê¶Œ(ì¶©ë¶, ì¶©ë‚¨, ì„¸ì¢…, ëŒ€ì „)": 4, "ì „ë¼ê¶Œ(ì „ë¶, ì „ë‚¨, ê´‘ì£¼)": 3, "ê²½ìƒê¶Œ(ê²½ë¶, ê²½ë‚¨, ë¶€ì‚°, ëŒ€êµ¬, ìš¸ì‚°, ì œì£¼)": 6}

def pick_region_mapping(codes_2digit: set[str]) -> dict:
    a_hits = len(set(CODE_TO_REGION_A) & codes_2digit)
    b_hits = len(set(CODE_TO_REGION_B) & codes_2digit)
    return CODE_TO_REGION_A if a_hits > b_hits else CODE_TO_REGION_B

def robust_region_from_records(df: pd.DataFrame) -> pd.Series:
    """
    í™˜ì ë°ì´í„°ì—ì„œ ê¶Œì—­ ë¼ë²¨ì„ ìµœëŒ€í•œ ê²¬ê³ í•˜ê²Œ ìƒì„±.
      1) 'ìš”ì–‘ê¸°ê´€ì†Œì¬ì§€' 1~5 â†’ REGION_MAP_1TO5
      2) ì‹œë„ì½”ë“œ(ë‘ ìë¦¬) â†’ A/B ì½”ë“œ ë§¤í•‘
      3) ì‹œë„ëª…(ì›ë˜/ì •ê·œí™”) â†’ NAME_TO_REGION/NORMNAME_TO_REGION
    """
    # 1) 1~5
    if "ìš”ì–‘ê¸°ê´€ì†Œì¬ì§€" in df.columns:
        s = pd.to_numeric(df["ìš”ì–‘ê¸°ê´€ì†Œì¬ì§€"], errors="coerce")
        if s.notna().any():
            mapped = s.map(REGION_MAP_1TO5)
            if mapped.notna().mean() >= 0.8:
                return mapped

    # 2) ìˆ«ìì½”ë“œ(ë‘ ìë¦¬/ë‹¤ì„¯ ìë¦¬) â†’ A/B
    code_cols = [c for c in ["ìš”ì–‘ê¸°ê´€ì†Œì¬ì§€", "ì‹œë„ì½”ë“œ", "CTPRVN_CD"] if c in df.columns]
    if code_cols:
        code_col = code_cols[0]
        two = df[code_col].astype(str).map(first2digits)
        mapping_used = pick_region_mapping(set(two.unique()))
        mapped = two.map(mapping_used)
        if mapped.notna().mean() >= 0.6:
            return mapped

    # 3) ì‹œë„ëª…
    name_cols = [c for c in ["ì‹œë„", "ì‹œë„ëª…", "CTP_KOR_NM", "ê´‘ì—­ì‹œë„", "ìš”ì–‘ê¸°ê´€ê´‘ì—­"] if c in df.columns]
    if name_cols:
        nm = df[name_cols[0]].astype(str)
        m1 = nm.map(NAME_TO_REGION)
        if m1.notna().any():
            return m1
        m2 = nm.map(lambda x: NORMNAME_TO_REGION.get(norm_nm(x), np.nan))
        return m2

    return pd.Series([np.nan] * len(df), index=df.index, dtype="object")

@st.cache_resource(show_spinner=False)
def build_region_gdf(geo_path: str) -> tuple[gpd.GeoDataFrame, dict, dict]:
    gdf = gpd.read_file(geo_path)

    # CRS ì²˜ë¦¬
    try:
        if gdf.crs is None:
            xmin, ymin, xmax, ymax = gdf.total_bounds
            if max(abs(xmin), abs(ymin), abs(xmax), abs(ymax)) > 200:
                gdf = gdf.set_crs(epsg=5179).to_crs(epsg=4326)
            else:
                gdf = gdf.set_crs(epsg=4326)
        else:
            gdf = gdf.to_crs(epsg=4326)
    except Exception:
        pass

    # ì§€ì˜¤ë©”íŠ¸ë¦¬ ìœ íš¨í™”
    try:
        from shapely.validation import make_valid
        gdf["geometry"] = gdf.geometry.apply(make_valid)
    except Exception:
        gdf["geometry"] = gdf.buffer(0)

    # ë©€í‹°í´ë¦¬ê³¤ ë¶„ë¦¬
    try:
        gdf = gdf.explode(index_parts=False)
    except Exception:
        gdf = gdf.explode()

    # ì½”ë“œ ê¸°ë°˜ ë§¤í•‘
    mapping_used = None
    gdf["ê¶Œì—­_code"] = np.nan
    if "CTPRVN_CD" in gdf.columns:
        gdf["code2"] = gdf["CTPRVN_CD"].astype(str).map(first2digits)
        mapping_used = pick_region_mapping(set(gdf["code2"].unique()))
        gdf["ê¶Œì—­_code"] = gdf["code2"].map(mapping_used)

    # ì´ë¦„ ê¸°ë°˜ ë§¤í•‘(ì›ë³¸ëª… + ì •ê·œí™”ëª…)
    gdf["ê¶Œì—­_name"] = np.nan
    if "CTP_KOR_NM" in gdf.columns:
        nm = gdf["CTP_KOR_NM"].astype(str)
        name_map1 = nm.map(NAME_TO_REGION)
        name_map2 = nm.map(lambda x: NORMNAME_TO_REGION.get(norm_nm(x), np.nan))
        gdf["ê¶Œì—­_name"] = name_map1.fillna(name_map2)

    # â˜… í•­ìƒ ì½”ë“œ ìš°ì„  + ì´ë¦„ ë³´ì •
    gdf["ê¶Œì—­"] = gdf["ê¶Œì—­_code"].astype("object")
    gdf["ê¶Œì—­"] = gdf["ê¶Œì—­"].where(gdf["ê¶Œì—­"].notna(), gdf["ê¶Œì—­_name"])

    # ì»¤ë²„ë¦¬ì§€ ë¦¬í¬íŠ¸
    unmapped = gdf[gdf["ê¶Œì—­"].isna()][["CTPRVN_CD", "CTP_KOR_NM"]].drop_duplicates()
    coverage = {
        "ì´ ì‹œë„ìˆ˜": int(gdf.drop_duplicates(subset=["CTPRVN_CD", "CTP_KOR_NM"]).shape[0]) if {"CTPRVN_CD","CTP_KOR_NM"}.issubset(gdf.columns) else int(gdf.shape[0]),
        "ì½”ë“œë§¤í•‘_ì»¤ë²„ë¦¬ì§€(%)": round(gdf["ê¶Œì—­_code"].notna().mean() * 100, 1),
        "ì´ë¦„ë§¤í•‘_ì»¤ë²„ë¦¬ì§€(%)": round(gdf["ê¶Œì—­_name"].notna().mean() * 100, 1),
        "ìµœì¢…ë§¤í•‘_ì»¤ë²„ë¦¬ì§€(%)": round(gdf["ê¶Œì—­"].notna().mean() * 100, 1),
        "ë¯¸ë§¤í•‘_ì‹œë„": unmapped.to_dict(orient="records"),
        "ì‚¬ìš©í•œ_ì½”ë“œë§¤í•‘": ("A" if mapping_used is CODE_TO_REGION_A else "B") if mapping_used else "N/A",
    }

    # íŠ¹ì • ì‹œë„ ë©´ì  ë””ë²„ê·¸
    dbg_names = ['ì¶©ì²­ë‚¨ë„','ì „ë¼ë‚¨ë„','ë¶€ì‚°ê´‘ì—­ì‹œ']
    dbg_area = {}
    for n in dbg_names:
        try:
            a = float(gdf.loc[gdf.get('CTP_KOR_NM','')==n, 'geometry'].area.sum())
            dbg_area[n] = a
        except Exception:
            dbg_area[n] = None
    coverage["ë””ë²„ê·¸_ë©´ì m2"] = {k: (None if v is None else round(v,2)) for k,v in dbg_area.items()}

    # ê¶Œì—­ ë‹¨ìœ„ dissolve
    region_gdf = gdf.dropna(subset=["ê¶Œì—­"]).dissolve(by="ê¶Œì—­", as_index=False)[["ê¶Œì—­", "geometry"]]
    region_gdf = gpd.GeoDataFrame(region_gdf, geometry="geometry", crs=gdf.crs)

    # ìµœì¢… ì•ˆì „ ë³´ì •
    try:
        region_gdf["geometry"] = region_gdf.buffer(0)
    except Exception:
        pass

    return region_gdf, {"mapping_used": mapping_used}, coverage

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë°ì´í„° ë¡œë”©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("ë°ì´í„° ì„ íƒ")
    st.divider()

GEO_CANDIDATES = ["/mnt/data/TL_SCCO_CTPRVN.json", "TL_SCCO_CTPRVN.json", "data/TL_SCCO_CTPRVN.json"]
geo_path = next((p for p in GEO_CANDIDATES if Path(p).exists()), GEO_CANDIDATES[0])

ALL_FILE = "all_df.csv"             # í˜¸í¡ê¸° ì „ì²´ ì›ì²œ
PNEU_FILE = "pneumonia_data.csv"    # íë ´ ì „ì²´ ì›ì²œ

def read_csv_or_stop(path):
    try:
        return pd.read_csv(path, encoding="utf-8-sig")
    except FileNotFoundError:
        st.error(f"'{path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

df_all_raw  = read_csv_or_stop(ALL_FILE)
df_pneu_raw = read_csv_or_stop(PNEU_FILE)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê³µí†µ ë¼ë²¨/ë§¤í•‘ ìƒìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TYPE_MAP = {10: "ì¢…í•©ë³‘ì› ì´ìƒ", 21: "ë³‘ì›", 28: "ìš”ì–‘ë³‘ì›", 29: "ì •ì‹ ë³‘ì›", 31: "ì˜ì›", 41: "ì¹˜ê³¼ë³‘ì›"}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‚¬ì´ë“œë°”: ì§ˆí™˜ í•„í„°(ëŒ€/ì¤‘/ìƒì„¸) + íë ´ ìƒì„¸ì½”ë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("ì„¸ë¶€ë¶„ë¥˜ í•„í„°")

    # ICD ì»¬ëŸ¼ ìë™ íƒìƒ‰(df_all ê¸°ì¤€)
    main_candidates = ["ì£¼ìƒë³‘ì½”ë“œ", "ì£¼ìƒë³‘", "ì£¼ìƒë³‘1", "ì£¼ì§„ë‹¨ì½”ë“œ", "ì£¼ì§„ë‹¨"]
    sub_candidates  = ["ë¶€ìƒë³‘ì½”ë“œ", "ë¶€ìƒë³‘", "ë¶€ìƒë³‘1", "ë¶€ì§„ë‹¨ì½”ë“œ", "ë¶€ì§„ë‹¨"]
    single_candidates = ["ìƒë³‘ì½”ë“œ", "ì§„ë‹¨ì½”ë“œ", "ICD10", "IC-10", "ì§ˆë³‘ì½”ë“œ", "ì£¼ìƒë³‘", "ì£¼ìƒë³‘ì½”ë“œ", "ìƒë³‘"]

    def find_cols(df):
        main = next((c for c in main_candidates if c in df.columns), None)
        sub  = next((c for c in sub_candidates if c in df.columns), None)
        single = next((c for c in single_candidates if c in df.columns), None)
        return main, sub, single

    main_col_all, sub_col_all, single_col_all = find_cols(df_all_raw)

    def canon(s): return normalize_icd(s)

    # ëŒ€ë¶„ë¥˜ ë§¤í•‘
    resp_disease_map = {
        "í˜¸í¡ê¸°ì§ˆí™˜": ["J",'A15','A16','A19',"S270",'P251',"B664","B583","A430","A420","J690","J691","J698","J853"],
        "ê°ê¸°": ["J00","J01","J02","J03","J04","J05","J06"],
        "ì¸í”Œë£¨ì—”ì": ["J09", "J10", "J11"],
        "ê²°í•µ": ["A15", "A16","A19"],
        "ë§Œì„±íì‡ ì§ˆí™˜(COPD)": ["J431", "J432","J438","J439","J40","J41","J42","J43","J44","J47"],
        "ì²œì‹": ["J45","J46"],
        # íë ´ ë£¨íŠ¸/ì—°ê´€
        "íë ´": ["B664","B583","A430","A420","J12", "J13", "J14", "J15", "J16", "J17", "J18", "J69","J85"],
        "ê¸°í‰": ["J93", "S270", "P251"]
    }

    # íë ´ ìƒì„¸ì½”ë“œ ë§ˆìŠ¤í„°
    pneumonia_codes_master = [
        "A420","A430","B583","B664",
        "J120","J121","J122","J128","J1280","J1288","J129",
        "J13","J14","J150","J151","J152","J153","J154","J155",
        "J156","J157","J158","J159","J160","J168","J170","J171",
        "J173","J178","J180","J181","J188","J189",
        "J690","J691","J698","J853"
    ]

    # í˜¸í¡ê¸° ì „ì²´(all_df) êµ¬ì„±
    def prepare_all_df(df_src: pd.DataFrame, main_col, sub_col, single_col) -> tuple[pd.DataFrame, str, str]:
        df2 = df_src.copy()
        if main_col is None and single_col is not None:
            main_col = single_col
        if sub_col is None:
            df2["_SUB_EMPTY_"] = ""
            sub_col = "_SUB_EMPTY_"
        for c in (main_col, sub_col):
            df2[c] = df2[c].apply(canon).astype("string")
        tb = tuple(resp_disease_map["ê²°í•µ"])
        pneumo_extra = tuple([p for p in resp_disease_map["ê¸°í‰"] if not p.startswith("J")])
        resp_mask = (
            df2[main_col].str.startswith("J", na=False) | df2[sub_col].str.startswith("J", na=False) |
            df2[main_col].str.startswith(tb, na=False) | df2[sub_col].str.startswith(tb, na=False) |
            df2[main_col].str.startswith(pneumo_extra, na=False) | df2[sub_col].str.startswith(pneumo_extra, na=False)
        )
        return df2[resp_mask].copy(), main_col, sub_col

    # 1) ëŒ€ë¶„ë¥˜ ì„ íƒ
    super_labels = ["ì „ì²´", "ê°ê¸°", "ì¸í”Œë£¨ì—”ì", "ê²°í•µ", "ë§Œì„±íì‡ ì§ˆí™˜(COPD)", "ì²œì‹", "íë ´", "ê¸°í‰"]
    sel_super = st.selectbox("ëŒ€ë¶„ë¥˜ ì„ íƒ", super_labels, index=0, key="super_select")

    # 2) ë°ì´í„°ì…‹ ì„ íƒ ë° ì¤‘/ìƒì„¸ í•„í„°
    if sel_super == "íë ´":
        df_base = df_pneu_raw.copy()
        m_p, s_p, one_p = find_cols(df_base)
        if m_p is None and one_p is not None:
            m_p = one_p
        if s_p is None:
            df_base["_SUB_EMPTY_"] = ""
            s_p = "_SUB_EMPTY_"
        for c in (m_p, s_p):
            df_base[c] = df_base[c].apply(canon).astype("string")

        pneu_roots = tuple(resp_disease_map["íë ´"])
        pool = pd.unique(pd.concat([df_base[m_p], df_base[s_p]], ignore_index=True)).astype(str)
        present_exact = {c for c in pool if c in set(pneumonia_codes_master)}
        present_prefix = {c for c in pool if any(c.startswith(pref) for pref in pneu_roots)}
        present = sorted(present_exact | present_prefix)

        sel_detail = st.multiselect(
            "íë ´ ìƒì„¸ ì½”ë“œ ì„ íƒ",
            options=["ì „ì²´"] + present,
            default=["ì „ì²´"],
            key="pneumonia_detail"
        )

        if "ì „ì²´" in sel_detail or len(sel_detail) == 0:
            mask = (
                df_base[m_p].isin(pneumonia_codes_master) | df_base[s_p].isin(pneumonia_codes_master) |
                df_base[m_p].str.startswith(pneu_roots, na=False) |
                df_base[s_p].str.startswith(pneu_roots, na=False)
            )
        else:
            sels = tuple(sel_detail)
            mask = (
                df_base[m_p].isin(sel_detail) | df_base[s_p].isin(sel_detail) |
                df_base[m_p].str.startswith(sels, na=False) |
                df_base[s_p].str.startswith(sels, na=False)
            )

        df_selected = df_base[mask].copy()
        used_source = "íë ´ ì „ì²´(pneumonia_data.csv)"
        chosen = "ì „ì²´" if ("ì „ì²´" in sel_detail or len(sel_detail) == 0) else ", ".join(sel_detail[:10]) + (" ..." if len(sel_detail) > 10 else "")
        st.caption(f"ë°ì´í„° ì†ŒìŠ¤: pneumonia_data.csv (íë ´ ì „ì²´) Â· ìƒì„¸={chosen}")

    else:
        if (main_col_all is None) and (sub_col_all is None) and (single_col_all is None):
            st.error("df_all.csvì—ì„œ ICD ì½”ë“œ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ì£¼/ë¶€ìƒë³‘ ë˜ëŠ” ìƒë³‘ì½”ë“œë¥˜ê°€ í•„ìš”)")
            st.stop()
        all_df, main_used, sub_used = prepare_all_df(df_all_raw, main_col_all, sub_col_all, single_col_all)

        if sel_super == "ì „ì²´":
            df_selected = all_df.copy()
            used_source = "í˜¸í¡ê¸°ì§ˆí™˜ ì „ì²´(df_all.csv)"
            st.caption("ì„¸ë¶€ë¶„ë¥˜ í•„í„° ë¯¸ì ìš© â€” í˜¸í¡ê¸°ì§ˆí™˜ ì „ì²´(J*, ê²°í•µ A15/A16/A19, ê¸°í‰ S270/P251 í¬í•¨).")
        else:
            roots = resp_disease_map.get(sel_super, [])
            present = []
            for r in roots:
                m = all_df[main_used].str.startswith(r, na=False) | all_df[sub_used].str.startswith(r, na=False)
                if m.any():
                    present.append(r)
            if not present:
                st.info(f"ì„ íƒí•œ ëŒ€ë¶„ë¥˜({sel_super})ì˜ ì½”ë“œê°€ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤. â†’ í˜¸í¡ê¸° ì „ì²´ë¡œ ëŒ€ì²´")
                df_selected = all_df.copy()
                used_source = "í˜¸í¡ê¸°ì§ˆí™˜ ì „ì²´(df_all.csv)"
            else:
                sel_mid = st.selectbox("ì¤‘ë¶„ë¥˜(ë£¨íŠ¸) ì„ íƒ", options=["ì „ì²´"] + present, index=0, key=f"mid_{sel_super}")
                if sel_mid == "ì „ì²´":
                    mask = False
                    for r in present:
                        mask = mask | all_df[main_used].str.startswith(r, na=False) | all_df[sub_used].str.startswith(r, na=False)
                    df_selected = all_df[mask].copy()
                    used_source = "í˜¸í¡ê¸°ì§ˆí™˜ ì „ì²´(df_all.csv)"
                    st.caption(f"ì ìš©ëœ ì„¸ë¶€ë¶„ë¥˜: {sel_super} / ì „ì²´ ë£¨íŠ¸({len(present)}ê°œ)")
                else:
                    codes_main = all_df.loc[all_df[main_used].str.startswith(sel_mid, na=False), main_used]
                    codes_sub  = all_df.loc[all_df[sub_used].str.startswith(sel_mid, na=False), sub_used]
                    subs_present = sorted(pd.Index(codes_main.tolist() + codes_sub.tolist()).unique())
                    sel_detail = st.multiselect(
                        f"ìƒì„¸ ì½”ë“œ ì„ íƒ ({sel_mid}*)",
                        options=["ì „ì²´"] + subs_present,
                        default=["ì „ì²´"],
                        key=f"detail_{sel_mid}"
                    )
                    if "ì „ì²´" in sel_detail or len(sel_detail) == 0:
                        mask = all_df[main_used].str.startswith(sel_mid, na=False) | all_df[sub_used].str.startswith(sel_mid, na=False)
                    else:
                        sels = tuple(sel_detail)
                        mask = (
                            all_df[main_used].isin(sel_detail) | all_df[sub_used].isin(sel_detail) |
                            all_df[main_used].str.startswith(sels, na=False) | all_df[sub_used].str.startswith(sels, na=False)
                        )
                    df_selected = all_df[mask].copy()
                    used_source = "í˜¸í¡ê¸°ì§ˆí™˜ ì „ì²´(df_all.csv)"
                    chosen = "ì „ì²´" if ("ì „ì²´" in sel_detail or len(sel_detail) == 0) else ", ".join(sel_detail[:10]) + (" ..." if len(sel_detail) > 10 else "")
                    st.caption(f"ì ìš©ëœ ì„¸ë¶€ë¶„ë¥˜: {sel_super} / {sel_mid} / {chosen}")

    # ì´í›„ ë‹¨ê³„ì—ì„œ ì“¸ ê³µìš© df
    df = df_selected.copy()
    st.caption(f"í˜„ì¬ ë ˆì½”ë“œ ìˆ˜(ì—°ë ¹ í•„í„° ì „): {len(df):,}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì—°ë ¹ëŒ€ í•„í„°(ì„ íƒ df ìœ„ì— ì ìš©)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("ì—°ë ¹ëŒ€ í•„í„°")
    age_col = next((c for c in ["ì—°ë ¹", "ë‚˜ì´"] if c in df.columns), None)
    if age_col is None or df[age_col].dropna().empty:
        st.info("ì—°ë ¹/ë‚˜ì´ ë°ì´í„°ê°€ ì—†ì–´ ì—°ë ¹ëŒ€ í•„í„°ë¥¼ í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    else:
        age_numeric = pd.to_numeric(df[age_col], errors="coerce")
        max_age_val = np.nanmax(age_numeric.values)
        max_bin = int(np.ceil(max(max_age_val, 0) / 10.0) * 10) if np.isfinite(max_age_val) else 10
        max_bin = max(10, max_bin)
        bins = list(range(0, max_bin + 10, 10))
        labels_age = [f"{b}ëŒ€" for b in bins[:-1]]
        df["ì—°ë ¹ëŒ€"] = pd.cut(age_numeric, bins=bins, right=False, labels=labels_age)
        df["ì—°ë ¹ëŒ€"] = df["ì—°ë ¹ëŒ€"].astype("string").fillna("ë¯¸ìƒ")

        selected_bands = []
        for lab in labels_age:
            if st.toggle(lab, value=True, key=f"ageband_{lab}"):
                selected_bands.append(lab)
        if selected_bands:
            df = df[df["ì—°ë ¹ëŒ€"].isin(selected_bands)]
        st.caption("ì„ íƒëœ ì—°ë ¹ëŒ€: " + (", ".join(selected_bands) if selected_bands else "ëª¨ë‘(ë¯¸ìƒ ì œì™¸)"))
    st.caption(f"í˜„ì¬ ë ˆì½”ë“œ ìˆ˜(ì—°ë ¹ í•„í„° ì ìš© í›„): {len(df):,}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê³µí†µ ì „ì²˜ë¦¬(ì„ íƒ dfì— ëŒ€í•´)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê¶Œì—­ ë¼ë²¨(ê²¬ê³  ë§¤í•‘)
df["ê¶Œì—­"] = robust_region_from_records(df)

# ìš”ì–‘ê¸°ê´€ì¢…ë³„ ì½”ë“œ â†’ ëª…ì¹­
if "ìš”ì–‘ê¸°ê´€ì¢…ë³„" in df.columns:
    type_code_num = pd.to_numeric(df["ìš”ì–‘ê¸°ê´€ì¢…ë³„"], errors="coerce")
    df["ìš”ì–‘ê¸°ê´€ì¢…ë³„_ëª…ì¹­"] = type_code_num.map(TYPE_MAP).astype("string")
elif "ìš”ì–‘ê¸°ê´€ì¢…ë³„_ëª…ì¹­" in df.columns:
    df["ìš”ì–‘ê¸°ê´€ì¢…ë³„_ëª…ì¹­"] = df["ìš”ì–‘ê¸°ê´€ì¢…ë³„_ëª…ì¹­"].astype("string")
else:
    df["ìš”ì–‘ê¸°ê´€ì¢…ë³„_ëª…ì¹­"] = pd.Series(["ë¯¸ìƒ"] * len(df), dtype="string")

# ì„±ë³„ ë¼ë²¨
df["ì„±ë³„_label"] = df.get("ì„±ë³„", pd.Series(index=df.index)).map(map_sex)

# ë¶„ì„ ëŒ€ìƒë§Œ ë‚¨ê¸°ê¸°(ê¶Œì—­ ìœ íš¨)
df = df[df["ê¶Œì—­"].isin(VALID_REGIONS)].copy()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸: ìš”ì–‘ê¸°ê´€ì¢…ë³„ 'ë¶„í¬' (ì „ì²´ í‘œì‹œ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ìš”ì–‘ê¸°ê´€ì¢…ë³„ ë¶„í¬")
type_col = "ìš”ì–‘ê¸°ê´€ì¢…ë³„_ëª…ì¹­"
type_series = df[type_col].dropna().astype(str)

if type_series.empty:
    st.info("ìš”ì–‘ê¸°ê´€ì¢…ë³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    counts = type_series.value_counts()
    pct = (counts / counts.sum() * 100).round(2)
    cnt_df = series_to_df(counts, "ê±´ìˆ˜", type_col)
    pct_df = series_to_df(pct, "ë¹„ìœ¨(%)", type_col)
    type_df = cnt_df.merge(pct_df, on=type_col).sort_values("ê±´ìˆ˜", ascending=False)

    metric = st.radio("í‘œì‹œ ê¸°ì¤€", ["ê±´ìˆ˜", "ë¹„ìœ¨(%)"], horizontal=True)
    show_col = "ê±´ìˆ˜" if metric == "ê±´ìˆ˜" else "ë¹„ìœ¨(%)"
    chart_df = type_df.sort_values(show_col, ascending=False)

    cT1, cT2 = st.columns([2, 1], gap="large")
    with cT1:
        bar = (
            alt.Chart(chart_df)
            .mark_bar()
            .encode(
                x=alt.X(f"{show_col}:Q"),
                y=alt.Y(f"{type_col}:N", sort="-x", title="ìš”ì–‘ê¸°ê´€ì¢…ë³„"),
                tooltip=[type_col, "ê±´ìˆ˜", "ë¹„ìœ¨(%)"],
                color=alt.Color(f"{show_col}:Q", scale=alt.Scale(scheme="reds")),
            )
            .properties(height=max(280, 22 * len(chart_df)))
        )
        text = (
            alt.Chart(chart_df)
            .mark_text(align="left", baseline="middle", dx=4)
            .encode(x=f"{show_col}:Q", y=f"{type_col}:N", text=f"{show_col}:Q")
        )
        st.altair_chart(bar + text, use_container_width=True)
    with cT2:
        donut = px.pie(chart_df, values=show_col, names=type_col, hole=0.5, title="ìš”ì–‘ê¸°ê´€ ë¹„ì¤‘(ìš”ì•½)")
        donut.update_traces(textinfo="percent+label")
        st.plotly_chart(donut, use_container_width=True)
    with st.expander("í‘œ(ìš”ì–‘ê¸°ê´€ì¢…ë³„ ë¶„í¬)"):
        st.dataframe(type_df, use_container_width=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê¶Œì—­: ì‹œë„ìˆ˜ (í‘œì¤€í™”) ë§‰ëŒ€ + Choropleth ì§€ë„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ê¶Œì—­ë³„ ë¶„í¬ â€” ì‹œë„ìˆ˜(í‘œì¤€í™”) ê¸°ì¤€")

raw_counts = df["ê¶Œì—­"].value_counts().reindex(VALID_REGIONS, fill_value=0)
std_counts = raw_counts.astype(float).div(pd.Series(REGION_SIDO_N))
std_pct = (std_counts / std_counts.sum() * 100).round(2)
plot_df = series_to_df(std_pct, "ì‹œë„ìˆ˜ ë³´ì • ë¹„ìœ¨(%)", "ê¶Œì—­").sort_values("ì‹œë„ìˆ˜ ë³´ì • ë¹„ìœ¨(%)", ascending=False)

c1, c2 = st.columns([1, 1], gap="large")

with c1:
    chart = (
        alt.Chart(plot_df)
        .mark_bar()
        .encode(
            x=alt.X("ì‹œë„ìˆ˜ ë³´ì • ë¹„ìœ¨(%):Q", title="ë¹„ìœ¨(%)"),
            y=alt.Y("ê¶Œì—­:N", sort="-x"),
            tooltip=["ê¶Œì—­:N", "ì‹œë„ìˆ˜ ë³´ì • ë¹„ìœ¨(%):Q"],
            color=alt.Color("ì‹œë„ìˆ˜ ë³´ì • ë¹„ìœ¨(%):Q", scale=alt.Scale(scheme="reds")),
        )
        .properties(height=360)
    )
    text = (
        alt.Chart(plot_df)
        .mark_text(align="left", baseline="middle", dx=4)
        .encode(x="ì‹œë„ìˆ˜ ë³´ì • ë¹„ìœ¨(%):Q", y="ê¶Œì—­:N", text="ì‹œë„ìˆ˜ ë³´ì • ë¹„ìœ¨(%):Q")
    )
    st.altair_chart(chart + text, use_container_width=True)

with c2:
    try:
        region_gdf, debug_map, coverage = build_region_gdf(geo_path)
        map_df = region_gdf.merge(
            plot_df.rename(columns={"ì‹œë„ìˆ˜ ë³´ì • ë¹„ìœ¨(%)": "value"}),
            on="ê¶Œì—­", how="left"
        ).fillna({"value": 0})

        geojson_obj = json.loads(map_df.to_json())
        vmax = float(map_df["value"].max()) if len(map_df) else 0.0
        fig_map = px.choropleth(
            data_frame=map_df.drop(columns=["geometry"]),
            geojson=geojson_obj,
            locations="ê¶Œì—­",
            featureidkey="properties.ê¶Œì—­",
            color="value",
            color_continuous_scale="OrRd",
            range_color=(0, vmax if vmax > 0 else 1),
            labels={"value": "ì‹œë„ìˆ˜ ë³´ì • ë¹„ìœ¨(%)"},
        )
        fig_map.update_geos(fitbounds="locations", visible=False)
        fig_map.update_layout(height=420, margin=dict(l=0, r=0, t=60, b=0),
                              coloraxis_colorbar=dict(title="ì‹œë„ìˆ˜ ë³´ì •<br>ë¹„ìœ¨(%)"),
                                  title="ê¶Œì—­ë³„ ì‹œë„ìˆ˜ ë³´ì • ë¹„ìœ¨(%) ì§€ë„", title_y=0.95)
        st.plotly_chart(fig_map, use_container_width=True)
    except Exception as e:
        st.warning(f"ì§€ë„ë¥¼ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

with st.expander("í‘œ(ê¶Œì—­ ì‹œë„ìˆ˜ ë³´ì • ë¹„ìœ¨)"):
    st.dataframe(plot_df, use_container_width=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì„±ë³„ ë¶„ì„ (íŒŒì´ + ê¶Œì—­Ã—ì„±ë³„ ë§‰ëŒ€ + í‘œ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("### ì„±ë³„ ë¶„ì„")

c3, c4 = st.columns([1, 2], gap="large")

gender = df[df["ì„±ë³„_label"].notna()]["ì„±ë³„_label"]
g_pct = (gender.value_counts(normalize=True) * 100).reindex(["ë‚¨", "ì—¬"]).fillna(0).round(1)
g_df = series_to_df(g_pct, "ë¹„ìœ¨(%)", "ì„±ë³„")

with c3:
    pie = px.pie(
        g_df, values="ë¹„ìœ¨(%)", names="ì„±ë³„", color="ì„±ë³„",
        color_discrete_map={"ë‚¨": "#66c2a5", "ì—¬": "#fc8d62"},
        hole=0.4, title="ì„±ë³„ ë¶„í¬(%)"
    )
    pie.update_traces(textinfo="label+percent")
    st.plotly_chart(pie, use_container_width=True)
    with st.expander("í‘œ(ì„±ë³„ ì „ì²´ ë¹„ìœ¨)"):
        st.dataframe(g_df, use_container_width=True)

with c4:
    if len(df[df["ì„±ë³„_label"].notna()]) > 0:
        cross_counts = (
            df[df["ì„±ë³„_label"].notna()]
            .groupby(["ê¶Œì—­", "ì„±ë³„_label"], as_index=False)
            .size()
            .rename(columns={"size": "count"})
        )
        cross_counts["ë¹„ìœ¨(%)"] = cross_counts.groupby("ê¶Œì—­")["count"].transform(lambda s: s / s.sum() * 100)
        cross = cross_counts[["ê¶Œì—­", "ì„±ë³„_label", "ë¹„ìœ¨(%)"]]

        bar = (
            alt.Chart(cross)
            .mark_bar()
            .encode(
                x=alt.X("ë¹„ìœ¨(%):Q", title="ë¹„ìœ¨(%)"),
                y=alt.Y("ê¶Œì—­:N", sort="-x"),
                color=alt.Color("ì„±ë³„_label:N", title="ì„±ë³„",
                                scale=alt.Scale(domain=["ë‚¨", "ì—¬"], range=["#66c2a5", "#fc8d62"])),
                tooltip=["ê¶Œì—­:N", "ì„±ë³„_label:N", "ë¹„ìœ¨(%):Q"]
            )
            .properties(title="ê¶Œì—­ë³„ ì„±ë³„ ë¹„ìœ¨(ê¶Œì—­ ë‚´ %)", height=320)
        )
        st.altair_chart(bar, use_container_width=True)
        with st.expander("í‘œ(ê¶Œì—­Ã—ì„±ë³„ ë¹„ìœ¨)"):
            st.dataframe(cross.sort_values(["ê¶Œì—­", "ì„±ë³„_label"]), use_container_width=True)
    else:
        st.info("ì„±ë³„ ì •ë³´ê°€ ì—†ì–´ ê¶Œì—­Ã—ì„±ë³„ ë§‰ëŒ€ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í’‹ë…¸íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.caption("â“’ Respiratory Rehab / Pneumonia Insights â€” ê¶Œì—­ì€ ìš”ì–‘ê¸°ê´€ ì†Œì¬ì§€ ê¸°ì¤€, ê¶Œì—­ ë§‰ëŒ€ê·¸ë˜í”„ëŠ” ì‹œë„ìˆ˜ ë³´ì •(ì‹œë„ë‹¹ í‰ê· ) í›„ 100% ì •ê·œí™”í•œ ë¹„ìœ¨ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

